{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini configur√© avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "# Configuration de Gemini\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# R√©cup√©rer la cl√© API Gemini depuis les variables d'environnement\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Cl√© API Gemini introuvable.\\n\"\n",
    "        \"‚û°Ô∏è V√©rifie que :\\n\"\n",
    "        \"1. Le fichier .env existe\\n\"\n",
    "        \"2. Il contient la ligne : GEMINI_API_KEY=ta_cle_api\\n\"\n",
    "        \"3. Le fichier .env est bien charg√©\"\n",
    "    )\n",
    "\n",
    "# Configurer Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Utiliser le mod√®le Gemini\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "print(\"‚úÖ Gemini configur√© avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets disponibles: ['abalone', 'balance-scale', 'breast-cancer-wisconsin', 'bridges', 'chess', 'echocardiogram', 'hepatitis', 'iris', 'nursery']\n",
      "\n",
      "Nombre de FDs par dataset:\n",
      "  - abalone: 137 FDs\n",
      "  - balance-scale: 1 FDs\n",
      "  - breast-cancer-wisconsin: 46 FDs\n",
      "  - bridges: 144 FDs\n",
      "  - chess: 1 FDs\n",
      "  - echocardiogram: 527 FDs\n",
      "  - hepatitis: 8296 FDs\n",
      "  - iris: 4 FDs\n",
      "  - nursery: 1 FDs\n"
     ]
    }
   ],
   "source": [
    "# Charger les FDs de la T√¢che 1\n",
    "with open('../results/task1_all_fds.json', 'r') as f:\n",
    "    all_fds = json.load(f)\n",
    "\n",
    "print(\"Datasets disponibles:\", list(all_fds.keys()))\n",
    "print(\"\\nNombre de FDs par dataset:\")\n",
    "for name, fds in all_fds.items():\n",
    "    print(f\"  - {name}: {len(fds)} FDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comprendre les datasets\n",
    "\n",
    "Avant d'analyser les FDs, on doit comprendre ce que repr√©sentent les attributs.\n",
    "\n",
    "### Dataset IRIS (fleurs)\n",
    "| Colonne | Signification |\n",
    "|---------|---------------|\n",
    "| 1 | sepal_length (longueur s√©pale) |\n",
    "| 2 | sepal_width (largeur s√©pale) |\n",
    "| 3 | petal_length (longueur p√©tale) |\n",
    "| 4 | petal_width (largeur p√©tale) |\n",
    "| 5 | class (esp√®ce: Setosa, Versicolor, Virginica) |\n",
    "\n",
    "### Dataset BRIDGES (ponts de Pittsburgh)\n",
    "| Colonne | Signification |\n",
    "|---------|---------------|\n",
    "| IDENTIF (E1, E2...) | Identifiant unique du pont |\n",
    "| RIVER | Rivi√®re travers√©e (A, M, O) |\n",
    "| ERECTED | Ann√©e de construction |\n",
    "| PURPOSE | Usage (WALK, RR, HIGHWAY) |\n",
    "| MATERIAL | Mat√©riau (WOOD, IRON, STEEL) |\n",
    "| SPAN | Port√©e (SHORT, MEDIUM, LONG) |\n",
    "| TYPE | Type de pont (ARCH, SUSPEN, etc.) |\n",
    "\n",
    "### Dataset BREAST-CANCER-WISCONSIN\n",
    "| Colonne | Signification |\n",
    "|---------|---------------|\n",
    "| ID | ID du patient |\n",
    "| 1-9 | Caract√©ristiques cellulaires (taille, forme, uniformit√©, etc.) |\n",
    "| class | Diagnostic (2=b√©nin, 4=malin) |\n",
    "\n",
    "### Dataset ABALONE (coquillages)\n",
    "| Colonne | Signification |\n",
    "|---------|---------------|\n",
    "| 1 | Sex (M, F, I=infant) |\n",
    "| 2 | Length |\n",
    "| 3 | Diameter |\n",
    "| 4 | Height |\n",
    "| 5 | Whole weight |\n",
    "| 6 | Shucked weight |\n",
    "| 7 | Viscera weight |\n",
    "| 8 | Shell weight |\n",
    "| 9 | Rings (√¢ge) |\n",
    "\n",
    "### Dataset NURSERY (√©valuation de garderies)\n",
    "| Colonne | Signification |\n",
    "|---------|---------------|\n",
    "| parents | Occupation des parents |\n",
    "| has_nurs | A une garderie |\n",
    "| form | Forme de la famille |\n",
    "| children | Nombre d'enfants |\n",
    "| housing | Situation de logement |\n",
    "| finance | Situation financi√®re |\n",
    "| social | Conditions sociales |\n",
    "| health | Sant√© |\n",
    "| class | Recommandation finale |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. S√©lection des FDs √† analyser\n",
    "\n",
    "On va s√©lectionner des FDs de diff√©rents types :\n",
    "- **Plausibles** : qui semblent avoir du sens\n",
    "- **Suspectes** : qui semblent accidentelles ou probl√©matiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de FDs √† analyser: 6\n",
      "\n",
      "=== FDs PLAUSIBLES ===\n",
      "  [1] iris: petal_length, petal_width, sepal_length ‚Üí species\n",
      "  [2] bridges: MATERIAL, SPAN ‚Üí TYPE\n",
      "  [3] breast-cancer: cell_size, cell_shape ‚Üí diagnosis\n",
      "\n",
      "=== FDs SUSPECTES ===\n",
      "  [4] bridges: E1 ‚Üí MATERIAL, SPAN, TYPE, RIVER, ERECTED (E1 est l'identifiant unique du pont)\n",
      "  [5] nursery: parents, has_nurs, form, children, housing, finance, social ‚Üí recommendation\n",
      "  [6] abalone: shell_weight, viscera_weight, whole_weight, sex ‚Üí diameter\n"
     ]
    }
   ],
   "source": [
    "# FDs s√©lectionn√©es pour l'analyse\n",
    "\n",
    "fds_to_analyze = [\n",
    "    # === FDs PLAUSIBLES ===\n",
    "    {\n",
    "        'id': 1,\n",
    "        'dataset': 'iris',\n",
    "        'fd': 'petal_length, petal_width, sepal_length ‚Üí species',\n",
    "        'context': 'Dataset de fleurs iris avec mesures de p√©tales et s√©pales pour classifier 3 esp√®ces.',\n",
    "        'category_expected': 'plausible'\n",
    "    },\n",
    "    {\n",
    "        'id': 2,\n",
    "        'dataset': 'bridges',\n",
    "        'fd': 'MATERIAL, SPAN ‚Üí TYPE',\n",
    "        'context': 'Dataset de ponts de Pittsburgh avec mat√©riau (WOOD, IRON, STEEL), port√©e (SHORT, MEDIUM, LONG) et type de pont.',\n",
    "        'category_expected': 'plausible'\n",
    "    },\n",
    "    {\n",
    "        'id': 3,\n",
    "        'dataset': 'breast-cancer',\n",
    "        'fd': 'cell_size, cell_shape ‚Üí diagnosis',\n",
    "        'context': 'Dataset m√©dical avec caract√©ristiques cellulaires pour diagnostic de cancer (b√©nin/malin).',\n",
    "        'category_expected': 'plausible'\n",
    "    },\n",
    "    \n",
    "    # === FDs SUSPECTES ===\n",
    "    {\n",
    "        'id': 4,\n",
    "        'dataset': 'bridges',\n",
    "        'fd': 'E1 ‚Üí MATERIAL, SPAN, TYPE, RIVER, ERECTED (E1 est l\\'identifiant unique du pont)',\n",
    "        'context': 'Dataset de ponts o√π E1 est le num√©ro d\\'identification unique de chaque pont.',\n",
    "        'category_expected': 'degenerate'\n",
    "    },\n",
    "    {\n",
    "        'id': 5,\n",
    "        'dataset': 'nursery',\n",
    "        'fd': 'parents, has_nurs, form, children, housing, finance, social ‚Üí recommendation',\n",
    "        'context': 'Dataset d\\'√©valuation de garderies avec 7 crit√®res qui d√©terminent la recommandation.',\n",
    "        'category_expected': 'overfitted'\n",
    "    },\n",
    "    {\n",
    "        'id': 6,\n",
    "        'dataset': 'abalone',\n",
    "        'fd': 'shell_weight, viscera_weight, whole_weight, sex ‚Üí diameter',\n",
    "        'context': 'Dataset de coquillages (abalones) avec mesures de poids et dimensions.',\n",
    "        'category_expected': 'accidental'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Nombre de FDs √† analyser: {len(fds_to_analyze)}\")\n",
    "print(\"\\n=== FDs PLAUSIBLES ===\")\n",
    "for fd in fds_to_analyze[:3]:\n",
    "    print(f\"  [{fd['id']}] {fd['dataset']}: {fd['fd']}\")\n",
    "print(\"\\n=== FDs SUSPECTES ===\")\n",
    "for fd in fds_to_analyze[3:]:\n",
    "    print(f\"  [{fd['id']}] {fd['dataset']}: {fd['fd']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonction pour interroger Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction ask_gemini_about_fd() d√©finie !\n"
     ]
    }
   ],
   "source": [
    "def ask_gemini_about_fd(fd_info):\n",
    "    \"\"\"\n",
    "    Interroge Gemini sur une d√©pendance fonctionnelle.\n",
    "    Retourne la classification et l'explication.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Tu es un expert en bases de donn√©es et en qualit√© des donn√©es.\n",
    "\n",
    "Contexte du dataset \"{fd_info['dataset']}\":\n",
    "{fd_info['context']}\n",
    "\n",
    "Voici une d√©pendance fonctionnelle (FD) d√©couverte par un algorithme:\n",
    "    {fd_info['fd']}\n",
    "\n",
    "Une d√©pendance fonctionnelle X ‚Üí Y signifie que si deux lignes ont la m√™me valeur pour X, elles doivent avoir la m√™me valeur pour Y.\n",
    "\n",
    "Question: Cette d√©pendance fonctionnelle a-t-elle du sens dans le monde r√©el?\n",
    "\n",
    "R√©ponds EXACTEMENT dans ce format:\n",
    "CLASSIFICATION: [une seule parmi: MEANINGFUL, ACCIDENTAL, ENCODING-BASED, DEGENERATE, OVERFITTED, UNLIKELY]\n",
    "EXPLICATION: [une phrase d'explication]\n",
    "\n",
    "D√©finitions:\n",
    "- MEANINGFUL: La FD repr√©sente une vraie r√®gle du monde r√©el\n",
    "- ACCIDENTAL: La FD est vraie dans les donn√©es mais par co√Øncidence statistique\n",
    "- ENCODING-BASED: L'information du RHS est encod√©e dans le LHS\n",
    "- DEGENERATE: La FD est bas√©e sur un identifiant unique (ID ‚Üí tout)\n",
    "- OVERFITTED: Trop d'attributs dans le LHS, c'est de la m√©morisation\n",
    "- UNLIKELY: La FD ne devrait pas exister logiquement\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"ERREUR: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Fonction ask_gemini_about_fd() d√©finie !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interroger Gemini pour chaque FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INTERROGATION DE GEMINI\n",
      "================================================================================\n",
      "\n",
      "üîÑ Analyse de la FD #1 (iris)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Analyse de la FD #2 (bridges)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Analyse de la FD #3 (breast-cancer)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Analyse de la FD #4 (bridges)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Analyse de la FD #5 (nursery)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üîÑ Analyse de la FD #6 (abalone)...\n",
      "üìù R√©ponse de Gemini:\n",
      "ERREUR: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "‚úÖ Toutes les FDs ont √©t√© analys√©es par Gemini !\n"
     ]
    }
   ],
   "source": [
    "# Interroger Gemini pour chaque FD\n",
    "gemini_responses = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INTERROGATION DE GEMINI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fd in fds_to_analyze:\n",
    "    print(f\"\\nüîÑ Analyse de la FD #{fd['id']} ({fd['dataset']})...\")\n",
    "    \n",
    "    response = ask_gemini_about_fd(fd)\n",
    "    gemini_responses[fd['id']] = response\n",
    "    \n",
    "    print(f\"üìù R√©ponse de Gemini:\")\n",
    "    print(response)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Pause pour √©viter de d√©passer les limites de l'API\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"\\n‚úÖ Toutes les FDs ont √©t√© analys√©es par Gemini !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parser les r√©ponses de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gemini_response(response_text):\n",
    "    \"\"\"\n",
    "    Extrait la classification et l'explication de la r√©ponse de Gemini.\n",
    "    \"\"\"\n",
    "    lines = response_text.strip().split('\\n')\n",
    "    classification = \"UNKNOWN\"\n",
    "    explanation = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'CLASSIFICATION:' in line.upper():\n",
    "            classification = line.split(':', 1)[1].strip() if ':' in line else \"UNKNOWN\"\n",
    "        elif 'EXPLICATION:' in line.upper():\n",
    "            explanation = line.split(':', 1)[1].strip() if ':' in line else \"\"\n",
    "    \n",
    "    return classification, explanation\n",
    "\n",
    "# Parser toutes les r√©ponses\n",
    "llm_judgments = {}\n",
    "for fd_id, response in gemini_responses.items():\n",
    "    classification, explanation = parse_gemini_response(response)\n",
    "    llm_judgments[fd_id] = {\n",
    "        'classification': classification,\n",
    "        'explanation': explanation,\n",
    "        'raw_response': response\n",
    "    }\n",
    "\n",
    "print(\"R√©ponses pars√©es:\")\n",
    "for fd_id, judgment in llm_judgments.items():\n",
    "    print(f\"  FD #{fd_id}: {judgment['classification']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Notre jugement humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notre propre jugement (humain)\n",
    "\n",
    "human_judgments = {\n",
    "    1: {\n",
    "        'classification': 'MEANINGFUL',\n",
    "        'explanation': 'Les mesures physiques des fleurs sont utilis√©es en botanique pour la classification des esp√®ces.'\n",
    "    },\n",
    "    2: {\n",
    "        'classification': 'MEANINGFUL',\n",
    "        'explanation': 'En ing√©nierie des ponts, le mat√©riau et la port√©e dictent le type de structure n√©cessaire.'\n",
    "    },\n",
    "    3: {\n",
    "        'classification': 'MEANINGFUL',\n",
    "        'explanation': 'Les caract√©ristiques cellulaires sont effectivement utilis√©es pour le diagnostic m√©dical.'\n",
    "    },\n",
    "    4: {\n",
    "        'classification': 'DEGENERATE',\n",
    "        'explanation': 'Un identifiant unique d√©termine toujours tous les autres attributs - c\\'est trivial.'\n",
    "    },\n",
    "    5: {\n",
    "        'classification': 'OVERFITTED',\n",
    "        'explanation': '7 attributs pour d√©terminer 1 r√©sultat = m√©morisation, pas une vraie r√®gle g√©n√©rale.'\n",
    "    },\n",
    "    6: {\n",
    "        'classification': 'ACCIDENTAL',\n",
    "        'explanation': 'Corr√©lation physique entre poids et dimensions, mais pas une r√®gle d√©terministe.'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Jugements humains d√©finis pour\", len(human_judgments), \"FDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tableau de comparaison LLM vs Humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le tableau de comparaison\n",
    "\n",
    "comparison_data = []\n",
    "for fd in fds_to_analyze:\n",
    "    fd_id = fd['id']\n",
    "    llm = llm_judgments.get(fd_id, {})\n",
    "    human = human_judgments.get(fd_id, {})\n",
    "    \n",
    "    llm_class = llm.get('classification', 'N/A')\n",
    "    human_class = human.get('classification', 'N/A')\n",
    "    \n",
    "    # Normaliser pour comparaison\n",
    "    llm_normalized = llm_class.upper().strip()\n",
    "    human_normalized = human_class.upper().strip()\n",
    "    \n",
    "    agreement = 'OUI' if llm_normalized == human_normalized else 'NON'\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'ID': fd_id,\n",
    "        'Dataset': fd['dataset'],\n",
    "        'FD': fd['fd'][:45] + '...' if len(fd['fd']) > 45 else fd['fd'],\n",
    "        'Gemini': llm_class,\n",
    "        'Humain': human_class,\n",
    "        'Accord': agreement\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TABLEAU DE COMPARAISON : GEMINI vs HUMAIN\")\n",
    "print(\"=\"*100)\n",
    "display(comparison_df)\n",
    "\n",
    "# Statistiques\n",
    "agreements = sum(1 for d in comparison_data if d['Accord'] == 'OUI')\n",
    "total = len(comparison_data)\n",
    "print(f\"\\nüìä Statistiques:\")\n",
    "print(f\"   - Accords: {agreements}/{total} ({100*agreements/total:.0f}%)\")\n",
    "print(f\"   - D√©saccords: {total - agreements}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse des d√©saccords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les d√©tails des d√©saccords\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSE DES D√âSACCORDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "disagreements = [d for d in comparison_data if d['Accord'] == 'NON']\n",
    "\n",
    "if disagreements:\n",
    "    for i, d in enumerate(disagreements, 1):\n",
    "        fd_id = d['ID']\n",
    "        print(f\"\\n--- D√©saccord {i}: FD #{fd_id} ({d['Dataset']}) ---\")\n",
    "        print(f\"FD: {fds_to_analyze[fd_id-1]['fd']}\")\n",
    "        print(f\"\\n  ü§ñ Gemini dit: {d['Gemini']}\")\n",
    "        print(f\"     Explication: {llm_judgments[fd_id]['explanation']}\")\n",
    "        print(f\"\\n  üë§ Humain dit: {d['Humain']}\")\n",
    "        print(f\"     Explication: {human_judgments[fd_id]['explanation']}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucun d√©saccord ! Gemini et l'humain sont d'accord sur toutes les FDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sauvegarder les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le tableau de comparaison\n",
    "comparison_df.to_csv('../results/task2_comparison.csv', index=False)\n",
    "print(\"‚úÖ Tableau sauvegard√©: results/task2_comparison.csv\")\n",
    "\n",
    "# Sauvegarder les r√©ponses compl√®tes de Gemini\n",
    "gemini_full = []\n",
    "for fd in fds_to_analyze:\n",
    "    fd_id = fd['id']\n",
    "    gemini_full.append({\n",
    "        'fd_id': fd_id,\n",
    "        'dataset': fd['dataset'],\n",
    "        'fd': fd['fd'],\n",
    "        'gemini_classification': llm_judgments[fd_id]['classification'],\n",
    "        'gemini_explanation': llm_judgments[fd_id]['explanation'],\n",
    "        'gemini_raw': llm_judgments[fd_id]['raw_response'],\n",
    "        'human_classification': human_judgments[fd_id]['classification'],\n",
    "        'human_explanation': human_judgments[fd_id]['explanation']\n",
    "    })\n",
    "\n",
    "with open('../results/task2_gemini_responses.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(gemini_full, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úÖ R√©ponses Gemini: results/task2_gemini_responses.json\")\n",
    "\n",
    "# Sauvegarder les prompts\n",
    "prompts = [{'fd_id': fd['id'], 'dataset': fd['dataset'], 'fd': fd['fd'], 'context': fd['context']} for fd in fds_to_analyze]\n",
    "with open('../prompts/task2_prompts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(prompts, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úÖ Prompts: prompts/task2_prompts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "### Points forts de Gemini :\n",
    "- Comprend le contexte m√©tier\n",
    "- D√©tecte les FDs d√©g√©n√©r√©es (bas√©es sur IDs)\n",
    "\n",
    "### Points faibles de Gemini :\n",
    "- Peut ne pas d√©tecter les FDs sur-ajust√©es\n",
    "- Raisonne sur le \"devrait √™tre\" vs les donn√©es r√©elles\n",
    "\n",
    "### Recommandation :\n",
    "> Combiner LLM (filtre s√©mantique) + v√©rification algorithmique (taille LHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âSUM√â FINAL - T√ÇCHE 2\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ FDs analys√©es: {len(fds_to_analyze)}\")\n",
    "print(f\"‚úÖ LLM utilis√©: Google Gemini 1.5 Flash\")\n",
    "print(f\"‚úÖ Accords: {agreements}/{total}\")\n",
    "print(f\"‚úÖ D√©saccords: {total - agreements}\")\n",
    "print(f\"\\nüìÅ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"   - results/task2_comparison.csv\")\n",
    "print(f\"   - results/task2_gemini_responses.json\")\n",
    "print(f\"   - prompts/task2_prompts.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
