{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 : √âchantillonnage et Hypoth√®ses FD\n",
    "\n",
    "## Objectif\n",
    "√âtudier comment les d√©pendances fonctionnelles sugg√©r√©es par un LLM sur des **√©chantillons** peuvent diff√©rer de celles qui tiennent sur le **dataset complet**.\n",
    "\n",
    "## Ce qu'on doit faire :\n",
    "1. Cr√©er des √©chantillons (max 50 lignes) : al√©atoire et stratifi√©\n",
    "2. Montrer les √©chantillons au LLM et lui demander de sugg√©rer des FDs\n",
    "3. V√©rifier si ces FDs tiennent sur l'√©chantillon ET sur le dataset complet\n",
    "4. Identifier les faux positifs et les FDs trompeuses\n",
    "\n",
    "## Id√©e cl√©\n",
    "> L'√©chantillonnage cr√©e des **hypoth√®ses**, pas des **v√©rit√©s**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration de Claude (Anthropic)\nimport anthropic\nimport json\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display, Markdown\nimport time\nimport os\nfrom dotenv import load_dotenv\n\n# Charger les variables d'environnement depuis le fichier .env\n# Force le rechargement\nload_dotenv(override=True)\n\n# R√©cup√©rer la cl√© API Claude depuis les variables d'environnement\nCLAUDE_API_KEY = os.getenv(\"CLAUDE_API_KEY\")\n\n# Debug : afficher les premiers et derniers caract√®res de la cl√©\nif CLAUDE_API_KEY:\n    print(f\"üîë Cl√© charg√©e : {CLAUDE_API_KEY[:15]}...{CLAUDE_API_KEY[-5:]}\")\n    print(f\"üìè Longueur de la cl√© : {len(CLAUDE_API_KEY)} caract√®res\")\nelse:\n    raise ValueError(\n        \"‚ùå Cl√© API Claude introuvable.\\n\"\n        \"‚û°Ô∏è V√©rifie que :\\n\"\n        \"1. Le fichier .env existe\\n\"\n        \"2. Il contient la ligne : CLAUDE_API_KEY=ta_cle_api\\n\"\n        \"3. Le fichier .env est bien charg√©\"\n    )\n\n# Configurer le client Claude\nclient = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n\n# Test rapide de la connexion\ntry:\n    test_response = client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=10,\n        messages=[{\"role\": \"user\", \"content\": \"Dis juste 'OK'\"}]\n    )\n    print(f\"‚úÖ Claude configur√© avec succ√®s ! Test: {test_response.content[0].text}\")\nexcept Exception as e:\n    print(f\"‚ùå Erreur de connexion : {e}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Charger les datasets\ndatasets = {}\n\n# IRIS\niris_path = '../Datasets/iris/iris.data'\nif os.path.exists(iris_path):\n    datasets['iris'] = pd.read_csv(iris_path, header=None, \n                                    names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n    print(f\"‚úÖ iris: {datasets['iris'].shape}\")\nelse:\n    print(f\"‚ùå iris non trouv√©: {iris_path}\")\n\n# BRIDGES\nbridges_path = '../Datasets/pittsburgh+bridges/bridges.data.version1'\nif os.path.exists(bridges_path):\n    datasets['bridges'] = pd.read_csv(bridges_path, header=None,\n                                       names=['IDENTIF', 'RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', \n                                              'LENGTH', 'LANES', 'CLEAR-G', 'T-OR-D', 'MATERIAL',\n                                              'SPAN', 'REL-L', 'TYPE'])\n    print(f\"‚úÖ bridges: {datasets['bridges'].shape}\")\nelse:\n    print(f\"‚ùå bridges non trouv√©: {bridges_path}\")\n\n# ABALONE\nabalone_path = '../Datasets/abalone/abalone.data'\nif os.path.exists(abalone_path):\n    datasets['abalone'] = pd.read_csv(abalone_path, header=None,\n                                       names=['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight',\n                                              'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings'])\n    print(f\"‚úÖ abalone: {datasets['abalone'].shape}\")\nelse:\n    print(f\"‚ùå abalone non trouv√©: {abalone_path}\")\n\n# BREAST CANCER\nbc_path = '../Datasets/breast+cancer+wisconsin+original/breast-cancer-wisconsin.data'\nif os.path.exists(bc_path):\n    datasets['breast-cancer'] = pd.read_csv(bc_path, header=None,\n                                             names=['id', 'clump_thickness', 'uniformity_cell_size',\n                                                    'uniformity_cell_shape', 'marginal_adhesion',\n                                                    'single_epithelial_cell_size', 'bare_nuclei',\n                                                    'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class'])\n    print(f\"‚úÖ breast-cancer: {datasets['breast-cancer'].shape}\")\nelse:\n    print(f\"‚ùå breast-cancer non trouv√©: {bc_path}\")\n\nprint(f\"\\nüìä Datasets charg√©s: {list(datasets.keys())}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 2. Fonctions d'√©chantillonnage\n\nNous allons cr√©er 3 types d'√©chantillons :\n- **Al√©atoire** : s√©lection au hasard\n- **Stratifi√©** : garde les proportions de chaque groupe\n- **Biais√©** : sur-repr√©sente une cat√©gorie (pour montrer l'impact du biais)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def random_sample(df, n=50, seed=42):\n    \"\"\"\n    √âchantillon al√©atoire simple.\n    \"\"\"\n    n = min(n, len(df))\n    return df.sample(n=n, random_state=seed)\n\ndef stratified_sample(df, stratify_col, n=50, seed=42):\n    \"\"\"\n    √âchantillon stratifi√© bas√© sur une colonne.\n    Garde les proportions de chaque groupe.\n    \"\"\"\n    n = min(n, len(df))\n    # Calculer les proportions\n    proportions = df[stratify_col].value_counts(normalize=True)\n    \n    samples = []\n    for value, prop in proportions.items():\n        group = df[df[stratify_col] == value]\n        group_n = max(1, int(n * prop))  # Au moins 1 par groupe\n        group_n = min(group_n, len(group))\n        samples.append(group.sample(n=group_n, random_state=seed))\n    \n    result = pd.concat(samples)\n    # Ajuster si on a trop ou pas assez\n    if len(result) > n:\n        result = result.sample(n=n, random_state=seed)\n    return result\n\ndef biased_sample(df, bias_col, bias_value, n=50, seed=42):\n    \"\"\"\n    √âchantillon biais√© : sur-repr√©sente une valeur particuli√®re.\n    \"\"\"\n    n = min(n, len(df))\n    biased = df[df[bias_col] == bias_value]\n    others = df[df[bias_col] != bias_value]\n    \n    # 70% du groupe biais√©, 30% des autres\n    n_biased = min(int(n * 0.7), len(biased))\n    n_others = min(n - n_biased, len(others))\n    \n    sample_biased = biased.sample(n=n_biased, random_state=seed) if n_biased > 0 else pd.DataFrame()\n    sample_others = others.sample(n=n_others, random_state=seed) if n_others > 0 else pd.DataFrame()\n    \n    return pd.concat([sample_biased, sample_others])\n\nprint(\"‚úÖ Fonctions d'√©chantillonnage d√©finies\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. Cr√©er les √©chantillons"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cr√©er les √©chantillons pour chaque dataset\nsamples = {}\n\n# IRIS - √©chantillon al√©atoire et stratifi√© par classe\nif 'iris' in datasets:\n    df = datasets['iris']\n    samples['iris'] = {\n        'random': random_sample(df, n=30),\n        'stratified': stratified_sample(df, 'class', n=30)\n    }\n    print(f\"‚úÖ √âchantillons iris cr√©√©s (colonne stratifi√©e: class)\")\n\n# BRIDGES - √©chantillon al√©atoire et stratifi√© par MATERIAL\nif 'bridges' in datasets:\n    df = datasets['bridges']\n    samples['bridges'] = {\n        'random': random_sample(df, n=40),\n        'stratified': stratified_sample(df, 'MATERIAL', n=40)\n    }\n    print(f\"‚úÖ √âchantillons bridges cr√©√©s (colonne stratifi√©e: MATERIAL)\")\n\n# ABALONE - √©chantillon al√©atoire et stratifi√© par Sex\nif 'abalone' in datasets:\n    df = datasets['abalone']\n    samples['abalone'] = {\n        'random': random_sample(df, n=50),\n        'stratified': stratified_sample(df, 'Sex', n=50)\n    }\n    print(f\"‚úÖ √âchantillons abalone cr√©√©s (colonne stratifi√©e: Sex)\")\n\n# BREAST CANCER - √©chantillon al√©atoire et stratifi√© par class\nif 'breast-cancer' in datasets:\n    df = datasets['breast-cancer']\n    samples['breast-cancer'] = {\n        'random': random_sample(df, n=50),\n        'stratified': stratified_sample(df, 'class', n=50)\n    }\n    print(f\"‚úÖ √âchantillons breast-cancer cr√©√©s (colonne stratifi√©e: class)\")\n\nprint(f\"\\nüìä √âchantillons cr√©√©s pour: {list(samples.keys())}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Afficher un aper√ßu des √©chantillons\nfor dataset_name, dataset_samples in samples.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"Dataset: {dataset_name.upper()}\")\n    print(f\"{'='*60}\")\n    for sample_type, sample_df in dataset_samples.items():\n        print(f\"\\n--- {sample_type.upper()} ({len(sample_df)} lignes) ---\")\n        display(sample_df.head(5))"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. Fonction pour interroger le LLM sur les FDs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def ask_llm_for_fds(sample_df, dataset_name, sample_type):\n    \"\"\"\n    Montre un √©chantillon au LLM (Claude) et lui demande de sugg√©rer des FDs.\n    \"\"\"\n    # Convertir l'√©chantillon en texte (max 20 lignes pour le prompt)\n    sample_text = sample_df.head(20).to_string(index=False)\n    columns = list(sample_df.columns)\n    \n    prompt = f\"\"\"Tu es un expert en bases de donn√©es. Voici un √©chantillon de donn√©es du dataset \"{dataset_name}\".\n\nColonnes: {columns}\n\n√âchantillon ({len(sample_df)} lignes, voici les 20 premi√®res):\n{sample_text}\n\nEn analysant CET √âCHANTILLON UNIQUEMENT, quelles d√©pendances fonctionnelles (FDs) semblent tenir ?\n\nUne FD X ‚Üí Y signifie : si deux lignes ont la m√™me valeur pour X, elles ont la m√™me valeur pour Y.\n\nListe exactement 5 FDs que tu penses vraies dans cet √©chantillon.\nFormat de r√©ponse (une FD par ligne):\nFD1: colonne1 -> colonne2\nFD2: colonne1, colonne2 -> colonne3\netc.\n\nNe donne QUE les FDs, pas d'explications.\"\"\"\n    \n    try:\n        message = client.messages.create(\n            model=\"claude-3-haiku-20240307\",\n            max_tokens=1024,\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        return message.content[0].text\n    except Exception as e:\n        return f\"ERREUR: {str(e)}\"\n\nprint(\"‚úÖ Fonction ask_llm_for_fds() d√©finie (utilise Claude 3 Haiku)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interroger le LLM pour chaque √©chantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Collecter les FDs sugg√©r√©es par le LLM\n",
    "llm_suggested_fds = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INTERROGATION DU LLM POUR SUGG√âRER DES FDs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dataset_name, dataset_samples in samples.items():\n",
    "    llm_suggested_fds[dataset_name] = {}\n",
    "    \n",
    "    for sample_type, sample_df in dataset_samples.items():\n",
    "        print(f\"\\nüîÑ {dataset_name} - {sample_type}...\")\n",
    "        \n",
    "        response = ask_llm_for_fds(sample_df, dataset_name, sample_type)\n",
    "        llm_suggested_fds[dataset_name][sample_type] = response\n",
    "        \n",
    "        print(f\"üìù R√©ponse du LLM:\")\n",
    "        print(response)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        time.sleep(2)  # Pause pour l'API\n",
    "\n",
    "print(\"\\n‚úÖ Toutes les suggestions collect√©es !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parser les FDs sugg√©r√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_fd_response(response_text):\n",
    "    \"\"\"\n",
    "    Extrait les FDs de la r√©ponse du LLM.\n",
    "    Format attendu: \"colA, colB -> colC\" ou \"colA -> colB\"\n",
    "    \"\"\"\n",
    "    fds = []\n",
    "    lines = response_text.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        # Chercher le pattern \"X -> Y\" ou \"X ‚Üí Y\"\n",
    "        match = re.search(r'([^->‚Üí]+)\\s*[-‚Üí>]+\\s*([^->‚Üí]+)', line)\n",
    "        if match:\n",
    "            lhs = match.group(1).strip()\n",
    "            rhs = match.group(2).strip()\n",
    "            \n",
    "            # Nettoyer (enlever \"FD1:\", etc.)\n",
    "            lhs = re.sub(r'^FD\\d*:\\s*', '', lhs)\n",
    "            \n",
    "            # Parser le LHS (peut √™tre \"col1, col2\")\n",
    "            lhs_cols = [c.strip() for c in lhs.split(',')]\n",
    "            rhs_col = rhs.strip()\n",
    "            \n",
    "            fds.append({\n",
    "                'lhs': lhs_cols,\n",
    "                'rhs': rhs_col,\n",
    "                'fd_string': f\"{', '.join(lhs_cols)} -> {rhs_col}\"\n",
    "            })\n",
    "    \n",
    "    return fds\n",
    "\n",
    "# Parser toutes les r√©ponses\n",
    "parsed_fds = {}\n",
    "for dataset_name, dataset_responses in llm_suggested_fds.items():\n",
    "    parsed_fds[dataset_name] = {}\n",
    "    for sample_type, response in dataset_responses.items():\n",
    "        parsed_fds[dataset_name][sample_type] = parse_fd_response(response)\n",
    "\n",
    "# Afficher les FDs pars√©es\n",
    "print(\"FDs sugg√©r√©es par le LLM:\")\n",
    "for dataset_name, dataset_fds in parsed_fds.items():\n",
    "    print(f\"\\n{dataset_name.upper()}:\")\n",
    "    for sample_type, fds in dataset_fds.items():\n",
    "        print(f\"  {sample_type}: {len(fds)} FDs\")\n",
    "        for fd in fds:\n",
    "            print(f\"    - {fd['fd_string']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fonction de v√©rification des FDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fd_holds(df, lhs_cols, rhs_col):\n",
    "    \"\"\"\n",
    "    V√©rifie si une FD tient dans un DataFrame.\n",
    "    Retourne: (holds: bool, violations: int, total_groups: int)\n",
    "    \"\"\"\n",
    "    # V√©rifier que les colonnes existent\n",
    "    for col in lhs_cols + [rhs_col]:\n",
    "        if col not in df.columns:\n",
    "            return None, 0, 0  # Colonne non trouv√©e\n",
    "    \n",
    "    # Grouper par LHS et compter les valeurs uniques de RHS\n",
    "    grouped = df.groupby(lhs_cols)[rhs_col].nunique()\n",
    "    \n",
    "    # Une FD tient si chaque groupe a exactement 1 valeur pour RHS\n",
    "    violations = (grouped > 1).sum()\n",
    "    total_groups = len(grouped)\n",
    "    holds = violations == 0\n",
    "    \n",
    "    return holds, violations, total_groups\n",
    "\n",
    "def check_fd_approximate(df, lhs_cols, rhs_col):\n",
    "    \"\"\"\n",
    "    Calcule le taux de validit√© approximatif d'une FD.\n",
    "    Retourne le pourcentage de groupes qui respectent la FD.\n",
    "    \"\"\"\n",
    "    for col in lhs_cols + [rhs_col]:\n",
    "        if col not in df.columns:\n",
    "            return None\n",
    "    \n",
    "    grouped = df.groupby(lhs_cols)[rhs_col].nunique()\n",
    "    valid_groups = (grouped == 1).sum()\n",
    "    total_groups = len(grouped)\n",
    "    \n",
    "    if total_groups == 0:\n",
    "        return 0\n",
    "    \n",
    "    return (valid_groups / total_groups) * 100\n",
    "\n",
    "print(\"‚úÖ Fonctions de v√©rification d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Valider les FDs sur √©chantillons vs dataset complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valider chaque FD sugg√©r√©e\n",
    "validation_results = []\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"VALIDATION DES FDs SUGG√âR√âES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for dataset_name, dataset_fds in parsed_fds.items():\n",
    "    if dataset_name not in datasets:\n",
    "        continue\n",
    "    \n",
    "    full_df = datasets[dataset_name]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset: {dataset_name.upper()} ({len(full_df)} lignes)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for sample_type, fds in dataset_fds.items():\n",
    "        sample_df = samples[dataset_name][sample_type]\n",
    "        \n",
    "        print(f\"\\n--- FDs du {sample_type} ({len(sample_df)} lignes) ---\")\n",
    "        \n",
    "        for fd in fds:\n",
    "            lhs = fd['lhs']\n",
    "            rhs = fd['rhs']\n",
    "            fd_str = fd['fd_string']\n",
    "            \n",
    "            # V√©rifier sur l'√©chantillon\n",
    "            holds_sample, viol_sample, groups_sample = check_fd_holds(sample_df, lhs, rhs)\n",
    "            \n",
    "            # V√©rifier sur le dataset complet\n",
    "            holds_full, viol_full, groups_full = check_fd_holds(full_df, lhs, rhs)\n",
    "            \n",
    "            # Calculer la validit√© approximative\n",
    "            approx_sample = check_fd_approximate(sample_df, lhs, rhs)\n",
    "            approx_full = check_fd_approximate(full_df, lhs, rhs)\n",
    "            \n",
    "            if holds_sample is None or holds_full is None:\n",
    "                print(f\"  ‚ö†Ô∏è {fd_str} - Colonnes non trouv√©es\")\n",
    "                continue\n",
    "            \n",
    "            # D√©terminer le statut\n",
    "            if holds_sample and holds_full:\n",
    "                status = \"‚úÖ VRAIE (√©chantillon ET complet)\"\n",
    "                category = \"true_positive\"\n",
    "            elif holds_sample and not holds_full:\n",
    "                status = \"‚ùå FAUX POSITIF (vraie sur √©chantillon, fausse sur complet)\"\n",
    "                category = \"false_positive\"\n",
    "            elif not holds_sample and holds_full:\n",
    "                status = \"üî∂ Fausse sur √©chantillon mais vraie sur complet\"\n",
    "                category = \"sample_error\"\n",
    "            else:\n",
    "                status = \"‚ùå FAUSSE (√©chantillon ET complet)\"\n",
    "                category = \"false_negative\"\n",
    "            \n",
    "            print(f\"\\n  üìå {fd_str}\")\n",
    "            print(f\"     √âchantillon: {holds_sample} ({approx_sample:.1f}% valide, {viol_sample} violations)\")\n",
    "            print(f\"     Complet: {holds_full} ({approx_full:.1f}% valide, {viol_full} violations)\")\n",
    "            print(f\"     {status}\")\n",
    "            \n",
    "            validation_results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'sample_type': sample_type,\n",
    "                'fd': fd_str,\n",
    "                'holds_sample': holds_sample,\n",
    "                'holds_full': holds_full,\n",
    "                'approx_sample': approx_sample,\n",
    "                'approx_full': approx_full,\n",
    "                'violations_full': viol_full,\n",
    "                'category': category\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tableau r√©capitulatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le tableau r√©capitulatif\n",
    "if validation_results:\n",
    "    results_df = pd.DataFrame(validation_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"TABLEAU R√âCAPITULATIF\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    display(results_df[['dataset', 'sample_type', 'fd', 'holds_sample', 'holds_full', 'category']])\n",
    "    \n",
    "    # Statistiques\n",
    "    print(\"\\nüìä STATISTIQUES:\")\n",
    "    print(f\"   Total FDs analys√©es: {len(results_df)}\")\n",
    "    print(f\"   ‚úÖ Vraies positives: {(results_df['category'] == 'true_positive').sum()}\")\n",
    "    print(f\"   ‚ùå Faux positifs: {(results_df['category'] == 'false_positive').sum()}\")\n",
    "    print(f\"   ‚ùå Fausses: {(results_df['category'] == 'false_negative').sum()}\")\n",
    "else:\n",
    "    print(\"Aucun r√©sultat √† afficher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyse des Faux Positifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les faux positifs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSE DES FAUX POSITIFS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCes FDs semblaient vraies sur l'√©chantillon mais sont fausses sur le dataset complet.\")\n",
    "print(\"Cela montre que l'√©chantillonnage cache des violations !\\n\")\n",
    "\n",
    "if validation_results:\n",
    "    false_positives = [r for r in validation_results if r['category'] == 'false_positive']\n",
    "    \n",
    "    if false_positives:\n",
    "        for i, fp in enumerate(false_positives, 1):\n",
    "            print(f\"\\n--- Faux Positif {i} ---\")\n",
    "            print(f\"Dataset: {fp['dataset']}\")\n",
    "            print(f\"Type d'√©chantillon: {fp['sample_type']}\")\n",
    "            print(f\"FD: {fp['fd']}\")\n",
    "            print(f\"Validit√© sur √©chantillon: {fp['approx_sample']:.1f}%\")\n",
    "            print(f\"Validit√© sur complet: {fp['approx_full']:.1f}%\")\n",
    "            print(f\"Violations sur dataset complet: {fp['violations_full']}\")\n",
    "    else:\n",
    "        print(\"Aucun faux positif d√©tect√©.\")\n",
    "else:\n",
    "    print(\"Aucun r√©sultat disponible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sauvegarder les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les r√©sultats\n",
    "if validation_results:\n",
    "    results_df = pd.DataFrame(validation_results)\n",
    "    results_df.to_csv('../results/task3_validation_results.csv', index=False)\n",
    "    print(\"‚úÖ R√©sultats sauvegard√©s: results/task3_validation_results.csv\")\n",
    "\n",
    "# Sauvegarder les r√©ponses LLM\n",
    "with open('../results/task3_llm_responses.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(llm_suggested_fds, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úÖ R√©ponses LLM: results/task3_llm_responses.json\")\n",
    "\n",
    "# Sauvegarder les FDs pars√©es\n",
    "parsed_fds_serializable = {}\n",
    "for dataset, samples_dict in parsed_fds.items():\n",
    "    parsed_fds_serializable[dataset] = {}\n",
    "    for sample_type, fds in samples_dict.items():\n",
    "        parsed_fds_serializable[dataset][sample_type] = fds\n",
    "\n",
    "with open('../results/task3_parsed_fds.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(parsed_fds_serializable, f, indent=2, ensure_ascii=False)\n",
    "print(\"‚úÖ FDs pars√©es: results/task3_parsed_fds.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "### Ce qu'on a appris :\n",
    "\n",
    "1. **L'√©chantillonnage cache des violations**\n",
    "   - Une FD peut sembler vraie sur un petit √©chantillon\n",
    "   - Mais √™tre fausse sur le dataset complet\n",
    "\n",
    "2. **Les LLMs g√©n√©ralisent trop vite**\n",
    "   - Ils trouvent des patterns dans peu de donn√©es\n",
    "   - Ces patterns ne sont pas forc√©ment des r√®gles g√©n√©rales\n",
    "\n",
    "3. **Types de probl√®mes d√©tect√©s :**\n",
    "   - **Faux positifs** : FDs vraies sur √©chantillon, fausses sur complet\n",
    "   - **FDs non minimales** : Trop d'attributs dans le LHS\n",
    "   - **FDs trompeuses** : Semblent logiques mais sont accidentelles\n",
    "\n",
    "### Le√ßon cl√© :\n",
    "> Les patterns empiriques sur des √©chantillons ne sont PAS des contraintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âSUM√â FINAL - T√ÇCHE 3\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if validation_results:\n",
    "    results_df = pd.DataFrame(validation_results)\n",
    "    print(f\"\\n‚úÖ Datasets analys√©s: {results_df['dataset'].nunique()}\")\n",
    "    print(f\"‚úÖ FDs sugg√©r√©es par LLM: {len(results_df)}\")\n",
    "    print(f\"‚úÖ Faux positifs d√©tect√©s: {(results_df['category'] == 'false_positive').sum()}\")\n",
    "\n",
    "print(f\"\\nüìÅ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"   - results/task3_validation_results.csv\")\n",
    "print(f\"   - results/task3_llm_responses.json\")\n",
    "print(f\"   - results/task3_parsed_fds.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}